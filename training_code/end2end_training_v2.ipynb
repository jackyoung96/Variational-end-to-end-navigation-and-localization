{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-171d2fd6d3c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "\n",
    "pickle_file = 'end2end_dataset_v2.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    \n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    dev_dataset = save['dev_dataset']\n",
    "    dev_labels = save['dev_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    \n",
    "print(train_dataset[0].shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_tensor = TensorDataset(train_dataset[0],train_dataset[1],\n",
    "                             train_dataset[2],train_dataset[3],train_labels, torch.from_numpy(np.array(train_dataset[4])))\n",
    "dev_tensor = TensorDataset(dev_dataset[0],dev_dataset[1],\n",
    "                          dev_dataset[2],dev_dataset[3],dev_labels, torch.from_numpy(np.array(dev_dataset[4])))\n",
    "test_tensor = TensorDataset(test_dataset[0],test_dataset[1],\n",
    "                           test_dataset[2],test_dataset[3],test_labels, torch.from_numpy(np.array(test_dataset[4])))\n",
    "train_loader = DataLoader(train_tensor, batch_size = batch_size, shuffle=True, num_workers=2)\n",
    "dev_loader = DataLoader(dev_tensor, batch_size= batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg,(2,1,0))\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "img1, img2, img3, _map, labels, _ = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(img1[0]))\n",
    "imshow(torchvision.utils.make_grid(img2[0]))\n",
    "imshow(torchvision.utils.make_grid(img3[0]))\n",
    "imshow(torchvision.utils.make_grid(_map[0].unsqueeze(dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class e2dNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(e2dNet,self).__init__()\n",
    "        self.center_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=24, kernel_size = 5, stride = 2),\n",
    "#             nn.BatchNorm2d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=24,out_channels=36, kernel_size=5, stride =2),\n",
    "#             nn.BatchNorm2d(36),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=36,out_channels=48, kernel_size=3, stride =2),\n",
    "#             nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=48,out_channels=64, kernel_size=3, stride =1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.left_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=24, kernel_size = 5, stride = 2),\n",
    "#             nn.BatchNorm2d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=24,out_channels=36, kernel_size=5, stride =2),\n",
    "#             nn.BatchNorm2d(36),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=36,out_channels=48, kernel_size=3, stride =2),\n",
    "#             nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=48,out_channels=64, kernel_size=3, stride =1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.right_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=24, kernel_size = 5, stride = 2),\n",
    "#             nn.BatchNorm2d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=24,out_channels=36, kernel_size=5, stride =2),\n",
    "#             nn.BatchNorm2d(36),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=36,out_channels=48, kernel_size=3, stride =2),\n",
    "#             nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=48,out_channels=64, kernel_size=3, stride =1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.map_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=24, kernel_size = 5, stride = 2),\n",
    "#             nn.BatchNorm2d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=24, out_channels=36, kernel_size = 5, stride = 2),\n",
    "#             nn.BatchNorm2d(36),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=36, out_channels=48, kernel_size = 3, stride = 2),\n",
    "#             nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=24960, out_features=1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1000, out_features=100),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_features=100,out_features=3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.mean = nn.Linear(in_features=100,out_features=3)\n",
    "        self.sigma = nn.Sequential(\n",
    "            nn.Linear(in_features=100,out_features=3),\n",
    "            nn.Softplus()\n",
    "        )    \n",
    "        \n",
    "        \n",
    "    def forward(self,x_c,x_l,x_r,m):\n",
    "        x_c = self.center_conv(x_c)\n",
    "        x_l = self.left_conv(x_l)\n",
    "        x_r = self.right_conv(x_r)\n",
    "        m = self.map_conv(m)\n",
    "        x_con = torch.cat((x_c,x_l,x_r,m),dim=1)\n",
    "        x_con = self.fc(x_con)\n",
    "        phi = self.phi(x_con)\n",
    "        mean = self.mean(x_con)\n",
    "        sigma = self.sigma(x_con)\n",
    "        \n",
    "        return phi, mean, sigma\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss_NLL(phi,mean,sigma, data):\n",
    "    \n",
    "    p_g = torch.exp(-torch.div((mean-data)**2,(2*sigma**2)))\n",
    "    p_g = phi*torch.div(p_g,math.sqrt(2*math.pi)*sigma)\n",
    "#     p_g = phi*p_g\n",
    "\n",
    "    p_g = torch.sum(p_g,dim=1)\n",
    "    \n",
    "    return torch.sum(-torch.log(p_g))/batch_size\n",
    "\n",
    "\n",
    "\n",
    "#     return torch.min(-torch.log(p_g),\n",
    "#                -torch.log(torch.tensor(threshold).float().to(device)))/batch_size\n",
    "\n",
    "#     return torch.sum(phi*(mean-data)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_norm(x, p):\n",
    "    \n",
    "    norm = torch.pow(x,p)\n",
    "    norm = torch.sum(norm,dim=1)\n",
    "    \n",
    "    return torch.sum(torch.pow(norm,1/p))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(sig, c):\n",
    "    # lasso\n",
    "#     psi = torch.abs(torch.log(sig)-c)\n",
    "    \n",
    "    # ridge\n",
    "    psi = (torch.log(sig)-c)**2\n",
    "    \n",
    "    \n",
    "    \n",
    "    return torch.sum(psi)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper parameters ###\n",
    "\n",
    "C_regularizer = -5\n",
    "epoch = 100\n",
    "\n",
    "#########################\n",
    "\n",
    "# initialize model\n",
    "net = e2dNet()\n",
    "\n",
    "# Training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(net, trainloader, devloader , max_epoch, C_regularizer, optimizer, model_path='e2e_net_v2.pth'):\n",
    "    \n",
    "    dev_loss = 100000000\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        running_loss = 0\n",
    "        \n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            \n",
    "            \n",
    "            img_c, img_l, img_r, _map, label, _ = data\n",
    "            \n",
    "            img_c = img_c.float().to(device)\n",
    "            img_l = img_l.float().to(device)\n",
    "            img_r = img_r.float().to(device)\n",
    "            _map = _map.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            phi, mean, sigma = net(img_c,img_l,img_r,_map)\n",
    "#             print(phi,mean,sigma)\n",
    "#             loss = Loss_NLL(phi, mean, sigma, (label).unsqueeze(dim=1)*math.pi/180)\n",
    "            loss = Loss_NLL(phi, mean, sigma, (label).unsqueeze(dim=1))\n",
    "\n",
    "            loss += 1*p_norm(phi,0.5)\n",
    "#             loss += torch.sum(torch.norm(phi, 0.5, dim=1))/batch_size\n",
    "            loss += 0.1*regularizer(sigma, C_regularizer)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i%10 == 9:\n",
    "                print('[%d, %5d] training loss: %.3f' %\n",
    "                     (epoch+1, i+1, running_loss/10))\n",
    "                running_loss = 0\n",
    "        \n",
    "        # dev set evaluation\n",
    "        net.eval()\n",
    "        running_loss = 0\n",
    "        count = 0\n",
    "        for i, data in enumerate(devloader):\n",
    "            \n",
    "            img_c, img_l, img_r, _map, label, _ = data\n",
    "            \n",
    "            img_c = img_c.float().to(device)\n",
    "            img_l = img_l.float().to(device)\n",
    "            img_r = img_r.float().to(device)\n",
    "            _map = _map.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            phi, mean, sigma = net(img_c,img_l,img_r,_map)\n",
    "            loss = Loss_NLL(phi, mean, sigma, (label).unsqueeze(dim=1))\n",
    "\n",
    "            loss += 1*p_norm(phi,2)\n",
    "#             loss += torch.sum(torch.norm(phi, 0.5, dim=1))/batch_size\n",
    "            loss += 1*regularizer(sigma, C_regularizer)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            count = i+1\n",
    "        print('[%d, %5d] validation loss: %.3f' %\n",
    "             (epoch+1, i+1, running_loss/count))\n",
    "        \n",
    "        if dev_loss > running_loss/count:\n",
    "            dev_loss = running_loss/count\n",
    "            print(\"Training finished\")\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(net, train_loader, dev_loader, epoch, C_regularizer, optimizer, model_path='e2e_net_v2.4.pth')\n",
    "\n",
    "####\n",
    "\n",
    "# e2e_net_v2 : norm2 사용\n",
    "# e2e_net_v2.1 : norm 0.5 사용\n",
    "# e2e_net_v2.2 : norm 0.5, 가중치 0.01사용\n",
    "# e2e_net_v2.3 : norm 2 사용, 가중치 0.01, validation set 추가\n",
    "# e2e_net_v2.3 : norm 2 사용, 가중치 1, validation set 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def tensor2array(img,mean):\n",
    "#     print(img.shape)\n",
    "    im = np.transpose(img.numpy(),(2,1,0))\n",
    "    \n",
    "    im = Image.fromarray(im.astype(np.uint8))\n",
    "    \n",
    "    return im, mean.numpy()\n",
    "\n",
    "def draw_path(img, mean, GT):\n",
    "    img_o, theta = tensor2array(img, mean)\n",
    "    R = -1/ theta\n",
    "    if GT==0:\n",
    "        GT = 100000\n",
    "    else:\n",
    "        GT = -1/GT.numpy()\n",
    "#     print(R)\n",
    "    \n",
    "    img_o = draw_help(img_o,R[0],'red')\n",
    "    img_o = draw_help(img_o,R[1],'red')\n",
    "    img_o = draw_help(img_o,R[2],'red')\n",
    "    img_o = draw_help(img_o,GT,'blue')\n",
    "    \n",
    "    image_arr = np.asarray(img_o)\n",
    "    plt.imshow(image_arr)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "def draw_help(img, R, color):\n",
    "    h=1.7\n",
    "    h_t = 1280/720*h\n",
    "    y0=1.6\n",
    "    p=360\n",
    "\n",
    "    u0 = 540\n",
    "    v0 = 360\n",
    "\n",
    "    num = 1000\n",
    "\n",
    "    y = np.linspace(h,min(abs(R-y0)*2/3,50),num)\n",
    "    if R >= 0 :\n",
    "        x = R - np.sqrt(R**2 - (y+y0)**2)\n",
    "    else :\n",
    "        x = R + np.sqrt(R**2 - (y+y0)**2)  \n",
    "\n",
    "    u = (p*x*h_t/y/h + u0).astype(np.int32)\n",
    "    v = (p*h_t/y + v0).astype(np.int32)\n",
    "\n",
    "\n",
    "    point_list = []\n",
    "    for i in range(num):\n",
    "        point_list.append((u[i],v[i]))\n",
    "\n",
    "    im_path = ImageDraw.Draw(img)\n",
    "    im_path.point(point_list, fill= color)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, model_path='e2e_net.pth'):\n",
    "    net = e2dNet()\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    net.eval().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            \n",
    "            img_c, img_l, img_r, _map, label, img_o = data\n",
    "            data_size = img_c.shape[0]\n",
    "            \n",
    "            for num in range(batch_size):\n",
    "                if num >= data_size:\n",
    "                    break\n",
    "\n",
    "                imshow(torchvision.utils.make_grid(img_c[num]))\n",
    "                imshow(torchvision.utils.make_grid(img_l[num]))\n",
    "                imshow(torchvision.utils.make_grid(img_r[num]))\n",
    "                imshow(torchvision.utils.make_grid(_map[num].unsqueeze(dim=0)))\n",
    "\n",
    "                img_c_t = img_c[num].unsqueeze(dim=0).float().to(device)\n",
    "                img_l_t = img_l[num].unsqueeze(dim=0).float().to(device)\n",
    "                img_r_t = img_r[num].unsqueeze(dim=0).float().to(device)\n",
    "                _map_t = _map[num].unsqueeze(dim=0).float().to(device)\n",
    "                label_t = label[num].unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "                phi, mean, sigma = net(img_c_t,img_l_t,img_r_t,_map_t)\n",
    "\n",
    "                draw_path(img_o[num].float(), mean.squeeze().cpu(), label_t.squeeze().cpu())\n",
    "\n",
    "                print(\"result \",phi, mean, sigma)\n",
    "#                 print(label_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test(test_loader,model_path='e2e_net_v2.1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
